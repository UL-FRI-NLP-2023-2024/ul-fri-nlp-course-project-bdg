[
  {
    "ctx": "Lekcije ChatGPT za gospodarski razvoj",
    "ctx_link": "https://www.finance.si/lekcije-chatgpt-za-gospodarski-razvoj/a/9013056",
    "upvotes": 0,
    "content": "\nZadnja sprememba: murje 16.05.2023 14:06\nEVROPSKI PARLAMENT\n\nUmetna inteligenca: Priložnosti in tveganja\n\nUmetna inteligenca vse bolj vpliva na naša življenja. Spoznajte\npriložnosti in grožnje, ki jih predstavlja za varnost, demokracijo,\npodjetja in delo.\n\nBlaginja Evrope je v veliki meri odvisna od tega, kako ji bo uspelo\nizkoristiti potencial, ki ga predstavljajo podatki in z njimi\npovezane tehnologije. Umetna inteligenca lahko bistveno spremeni\nnaša življenja - na bolje ali slabše - in Evropski parlament je\nustanovil odbor za umetno inteligenco v digitalni dobi, ki je\npreučil vpliv te tehnologije in predlagal načrt EU za umetno\ninteligenco. Poslanci so pozvali tudi k oblikovanju zakonodaje o\numetni inteligenci, ki bo osredotočena na človeka. Predstavljamo\nnekaj ključnih priložnosti in tveganj, ki jih predstavlja umetna\ninteligenca.\n\nwww.europarl.europa....n-tveganja\n\nGEOFFREY HINTON\n\n\"Boter umetne inteligence\" svari pred nevarnostmi te\ntehnologije\n\nGeoffrey Hinton, ki se ga je prijel vzdevek \"boter umetne\ninteligence\", je potrdil, da je prejšnji teden zapustil Google, da\nbi opozarjal na \"nevarnosti\" tehnologije, ki jo je pomagal\nrazviti.\n\nHintonovo pionirsko delo na nevronskih mrežah, računalniških\nsistemih, oblikovanih po vzoru človeških možganov in živčnega\nsistema, je oblikovalo sisteme umetne inteligence, ki poganjajo\nštevilne današnje proizvode, poroča CNN.\n\nDesetletje je delno delal pri ameriškem tehnološkem velikanu\nGoogle, kjer je pomagal razvijati umetno inteligenco, a je medtem\npostal zaskrbljen zaradi tehnologije in svoje vloge v njenem\nrazvoju.\n\n\"Tolažim se z običajnim izgovorom, da če jaz ne bi tega počel, bi\nnekdo drug,\" je Hinton dejal za časopis New York Times, ki je prvi\nporočal o njegovi odločitvi.\n\nKot je pojasnil v ponedeljek, je z Googla odšel, da bi lahko\nsvobodno govoril o tveganjih umetne inteligence, ne pa iz želje, da\nbi kritiziral to podjetje, za katero je dejal, da je delovalo \"zelo\nodgovorno\".\n\nDo Hintonove odločitve prihaja v času, ko vse več politikov,\norganizacij in poznavalcev opozarja na možnost, da bi novi programi\numetne inteligence lahko širili lažne informacije in ukinjali\ndelovna mesta.\n\nV ospredu razvoja tovrstnih programov so OpenAI, Microsoft in\nGoogle, podobno tehnologijo pa razvijajo tudi IBM, Amazon, Baidu in\nTencent.\n\nMarca so vidni posamezniki na področju tehnologije objavili javno\npismo s pozivom, naj podjetja za najmanj pol leta prenehajo\nrazvijati sisteme umetne inteligence, kot razlog pa so navedli\n\"velika tveganja za družbo in človeštvo\".\n\nHinton je v pogovoru za New York Times izrazil zaskrbljenost glede\nmožnosti, da bi umetna inteligenca ukinila delovna mesta in\nustvarila svet, kjer številni ljudje \"ne bodo mogli vedeti več, kaj\nje res\". Opozoril je tudi na presunljiv tempo razvoja\ntehnologije.\n\nKot je dejal, je včasih mislil, da umetna inteligenca ne bo\npametnejša od ljudi še vsaj od 30 do 50 let, celo več. \"Očitno ne\nmislim več tako,\" je dejal.\n\nŽe leta 2021 je napovedal, da bo umetna inteligenca preobrazila\ndružbo na načine, ki jih ne razumemo popolnoma in katerih učinki ne\nbodo samo dobri. Umetna inteligenca bo okrepila zdravstvo, a bo\ntudi odprla možnosti za smrtonosna avtonomna orožja, je\ndejal.\n\nwww.rtvslo.si/znanos...ije/666749\n\n7 NEVARNOSTI\n\nZnanstveniki opozarjajo: To je sedem največjih nevarnosti, ki jih\nprinaša umetna inteligenca\nSeznam znanstvenikov, ki javno opozarjajo na nevarnosti\nneregulirane umetne inteligence, se vsak dan povečuje.\n\nSeznam znanstvenikov, ki javno opozarjajo na nevarnosti\nneregulirane umetne inteligence, ki se hitro razvija v največjih\nsvetovnih tehnoloških laboratorijih, se vsak dan povečuje. Mnogi se\nsprašujejo, česa točno se strokovnjaki bojijo, ko gre za\ntehnologijo prihodnosti, ki je že del vsakdana.\n\nKratkoročno, srednjeročno in dolgoročno tveganje, da nam umetna\ninteligenca ne bo koristila, se nanaša na zmanjševanje delovnih\nmest, izgubo zasebnosti, preplavljanje javnega diskurznega prostora\nz lažnimi ali izkrivljenimi vsebinami, diskriminacijo, poglabljanje\ndružbeno- gospodarsko vrzeli, pretrese na trgih in najbolj\napokaliptična možnost - vzpon robotov ubijalcev ali vsaj njihov\npadec v napačne roke.\n\nNajnovejši znanstvenik, ki je svetu poslal dramatično sporočilo,\nGeoffrey Hinton, je eden od graditeljev sistemov za umetno\ninteligenco. Hinton je pravkar podal odstopno izjavo iz Googla,\nkjer je delal kot raziskovalec, s pojasnilom, da »želi svobodo, da\nsvetu pripoveduje o nevarnostih nadaljnjega razvoja umetne\ninteligence brez strogih pravil«.\n\nV središču kritikov je več tveganj, ki jih prinaša umetna\ninteligenca.\n\n1. Družbena manipulacija\nJe že del sveta, v katerem živimo. Družbeni mediji so namreč s\nsvojimi avtonomnimi algoritmi zelo učinkoviti pri ciljanem trženju.\nVedo, kdo smo, kaj nam je všeč in so izjemno spretni pri ugibanju,\nkaj mislimo.\n\nStrah, da umetna inteligenca zmore in na kakšen način zmore\nmanipulirati z našim vedenjem, vzbujajo primeri, med katerimi je\nnajnovejši tisti s Ferdinandom Marcosom mlajšim, ki je z vojsko\ntrolov na družbenem omrežju TikTok, osvojil glasove mlajših\nFilipincev na volitvah lani. A to ni osamljen primer.\n\nObstaja možnost, da je podjetje Cambridge Analytica leta 2016\nuporabilo zasebne podatke 50 milijonov uporabnikov Facebooka, da bi\nvplivalo na izid ameriških predsedniških volitev, na katerih je\nzmagal Donald Trump, in referendum o brexitu. Obe »odločitvi\nljudstva« sta imeli daljnosežne posledice. Recept je preprost:\nalgoritmi in zasebni podatki se uporabljajo za identifikacijo\nposameznika, ki je tarča propagande in manipulacije.\n\nŽe zdaj je dovolj težko ločiti umetno inteligenco od resničnih\nljudi, zaradi česar je vpliv umetne inteligence v virtualnem svetu\nizjemen.\n\n2. Izguba služb\nUmetna inteligenca bi lahko mnoge pustila brez dela in ta realnost\nbi lahko bila bližje, kot si mnogi mislijo. To ne velja samo za\nnajtežje poklice, temveč tudi za tiste, ki po besedah ​​Maxa Erika\nTegmarka, fizika in velikega kritika nenadzorovanega razvoja umetne\ninteligence, človeška življenja polnijo s smislom. Poleg tega\numetna inteligenca bolj ogroža dela belih ovratnikov kot fizične\ndelavce. AI se že pogosto uporablja v trženju, proizvodnji in\nzdravstvu.\n\nToda po ocenah Goldman Sachsa bi lahko računalniki popolnoma\nprevzeli 18 odstotkov delovnih mest na svetovni ravni. Strateg\nChris Messina, ustvarjalec hashtaga (#), pravi, da so naslednje\ntarče robotskih prevzemov računovodski in pravni poklici. »V tem\nsektorju bomo videli velike pretrese,« je prepričan Messina.\n\n3. Izguba zasebnosti\nRazvoj tehnologije je omogočil spremljanje in analizo vsega, kar\nposamezniki počnejo na spletu, pa tudi na fizičnem nivoju. Kamere\nso skoraj povsod, algoritmi za prepoznavanje obrazov pa dobro vedo,\nkdo je kdo. Na podlagi teh sistemov je bil zgrajen nekoliko\ngrozljiv kitajski družbeni rating program, po katerem poskuša\noceniti vedenje 1,4 milijarde Kitajcev. Obnašanja, ki se beležijo\nza ocenjevanje občanov, so kajenje v prostorih, kjer je kajenje\nprepovedano, prečkanje ceste na mestih, kjer to ni dovoljeno ali na\nprimer koliko časa so porabili za igranje video iger. Takšen Big\nBrother ne pomeni le vdora v zasebnost, temveč tudi možnost začetka\ndružbenega zatiranja.\n\n4. Diskriminacija\nNe gre samo za diskriminacijo in družbene predsodke, ki so bili\nopaženi pri strojnem učenju in kjer so rasne manjšine in ženske v\nslabšem položaju na Zahodu. Ker lahko stroji zbirajo, sledijo in\nanalizirajo podatke o posameznikih, lahko te informacije tudi\nuporabijo proti njim. Primeri vključujejo zavarovalnico, ki »ve«,\nda oseba pogosto govori po mobilnem telefonu, ali delodajalca, ki\nnoče zaposliti osebe zaradi »nizkih socialnih točk«. En primer je\nameriška policija, ki uporablja policijske algoritme za\nnapovedovanje prizorišč zločina. Na te algoritme vplivajo stopnje\naretacij, ki nesorazmerno prizadenejo črnske soseske in ustvarjajo\nbolj zatiralsko vzdušje v teh delih mest.\n\n5. Slabitev etike in dobre volje\nNa to je opozoril tudi papež Frančišek, ko je govoril o svetu, ki\nse rojeva s prihodom umetne inteligence. Nova tehnologija bo\nspremenila življenja ljudi tako kot internet v devetdesetih letih.\n»Če tako imenovani tehnološki napredek človeštva postane sovražnik\nskupnega dobrega, bo to vodilo v regresijo v obliko barbarstva, v\nkaterem narekuje zakon močnejšega,« je dejal papež.\n\nNajveč skrbi je povzročil ChatGPT, umetna inteligenca, katere\nodkritje je nedavno razburilo svetovno javnost. Uporabniki so\nnamreč z novo tehnologijo pobegnili na primer od pisanja esejev,\nkar je sprožilo razprave o vplivu na poštenost v akademskem\nživljenju, pa tudi na ustvarjalnost in umetnost.\n\n6. Samovodljivo orožje\nMnogi so prepričani, da bo jedrsko oboroževalno tekmo nadomestilo\navtonomno oboroževalno tekmo.\n\nPred nekaj leti je ruski predsednik Vladimir Putin v govoru pred\nštudenti ruske univerze izjavil: »Umetna inteligenca je prihodnost\nne le za Rusijo, ampak tudi za človeštvo. Kdor koli bo postal\nvodilni na tem področju, bo postal vladar sveta.« Leta 2016 je\n30.000 znanstvenikov podpisalo peticijo, ki je zahtevala ustavitev\nraziskav avtonomnega orožja. Toda poleg dejstva, da bi smrtonosno\norožje lahko ušlo izpod nadzora in razvilo lastno voljo, kar sodi v\nsfero hipotetičnih napovedi in ZF filmov, obstaja objektivna\nnevarnost, da takšno orožje pride v napačne roke, posameznikov ali\nskupin, ki nimajo velike vrednosti za človeško življenje. Ko bi se\nzačeli, bi jih bilo težko ustaviti ali premagati.\n\n7. Poglabljanje socialno-ekonomskih razlik in pretresi na\ntrgu\nDružbeni razkorak je ena od nevarnosti zaposlovanja na delovnem\nmestu, ki ga vodi umetna inteligenca. Ugotavljanje lastnosti\nkandidatov z analizo glasu in obraza po mnenju strokovnjakov\nprinaša tveganje diskriminacije pri zaposlovanju. Prav tako se je\nže izkazalo, da so fizičnim delavcem zaradi uvajanja avtomatizacije\npadle plače, »belim ovratnikom« pa so bolj ali manj ostali\nnepoškodovani, nekateri pa so celo izboljšali svoje plačilne\nliste.\n\nZaradi avtomatizacije poslovanja v finančnem sektorju obstaja\nbojazen, da bi lahko naslednjo veliko krizo povzročila umetna\ninteligenca. To se je že dvakrat zgodilo zaradi programske opreme,\nki je »ponorela« in z brezglavim ravnanjem povzročila kaos na\ntrgu.\n\nwww.slovenskenovice....teligenca/\n\nNajvečja nevarnost umetne inteligence je, da ljudje prezgodaj\nsklepajo, da jo razumejo.\nEliezer Yudkowsky\n\nMISEL DNEVA\n\n“Težava je, ker je digitalna tehnologija prišla v zibko. Kot povsod\nsmo starši zgled, velikokrat zelo slab. Ko dajo starši enoletnemu\notroku v roke telefon z risankami, da imajo mir, je to težava na\ndolgi rok.”\nUroš Perko, strokovni delavec v Skupnosti Srečanje\nTorek, 4.oktober 2022\nwww.primorske.si\n\nBOB DNEVA\n\n\"Spletna konferenca ti ne omogoča tega, da bi se nagnil k sosedu in\nmu šepetaje dal cinično pripombo. Zdi se mi, da izgubljamo\nsposobnosti iskrene komunikacije, spoznavanja ljudi,\ndiskusije.\"\nDr. Rok Tkavc, mikrobiolog\nPonedeljek, 17.aprila 2023\nwww.vecer.com",
    "author": "murje"
  },
  {
    "ctx": "Lekcije ChatGPT za gospodarski razvoj",
    "ctx_link": "https://www.finance.si/lekcije-chatgpt-za-gospodarski-razvoj/a/9013056",
    "upvotes": 0,
    "content": "\nBOB DNEVA\n\n\"Pri uporabi socialnih omrežij bi bila smiselna regulativa. Ne\nmoremo od staršev pričakovati, da bodo vedno vse zmogli in znali\nčisto sami. Kot pri cigaretah - bolje, da se mladim sploh ne\nprodajajo.\"\nNina Šenica, pedopsihiatrinja\nPonedeljek, 5. junija 2023\nwww.vecer.com",
    "author": "murje"
  },
  {
    "ctx": "Lekcije ChatGPT za gospodarski razvoj",
    "ctx_link": "https://www.finance.si/lekcije-chatgpt-za-gospodarski-razvoj/a/9013056",
    "upvotes": 3,
    "content": "\nmojemu menedzerju so na neki menedzerski konferenci prodali idejo,\nda do 2030 programerjev (med katerimi sem tudi sam). taisti model\nme potem cele dneve zasipa s ticketi in requesti, ki jih je treba\nnarest asap.\n\nkomaj cakam tole leto 2030, ker bi si rad vsaj malo oddahnil...",
    "author": "shevchenko"
  },
  {
    "ctx": "Lekcije ChatGPT za gospodarski razvoj",
    "ctx_link": "https://www.finance.si/lekcije-chatgpt-za-gospodarski-razvoj/a/9013056",
    "upvotes": 0,
    "content": "\nZadnja sprememba: murje 16.05.2023 14:06\nEVROPSKI PARLAMENT\n\nUmetna inteligenca: Priložnosti in tveganja\n\nUmetna inteligenca vse bolj vpliva na naša življenja. Spoznajte\npriložnosti in grožnje, ki jih predstavlja za varnost, demokracijo,\npodjetja in delo.\n\nBlaginja Evrope je v veliki meri odvisna od tega, kako ji bo uspelo\nizkoristiti potencial, ki ga predstavljajo podatki in z njimi\npovezane tehnologije. Umetna inteligenca lahko bistveno spremeni\nnaša življenja - na bolje ali slabše - in Evropski parlament je\nustanovil odbor za umetno inteligenco v digitalni dobi, ki je\npreučil vpliv te tehnologije in predlagal načrt EU za umetno\ninteligenco. Poslanci so pozvali tudi k oblikovanju zakonodaje o\numetni inteligenci, ki bo osredotočena na človeka. Predstavljamo\nnekaj ključnih priložnosti in tveganj, ki jih predstavlja umetna\ninteligenca.\n\nwww.europarl.europa....n-tveganja\n\nGEOFFREY HINTON\n\n\"Boter umetne inteligence\" svari pred nevarnostmi te\ntehnologije\n\nGeoffrey Hinton, ki se ga je prijel vzdevek \"boter umetne\ninteligence\", je potrdil, da je prejšnji teden zapustil Google, da\nbi opozarjal na \"nevarnosti\" tehnologije, ki jo je pomagal\nrazviti.\n\nHintonovo pionirsko delo na nevronskih mrežah, računalniških\nsistemih, oblikovanih po vzoru človeških možganov in živčnega\nsistema, je oblikovalo sisteme umetne inteligence, ki poganjajo\nštevilne današnje proizvode, poroča CNN.\n\nDesetletje je delno delal pri ameriškem tehnološkem velikanu\nGoogle, kjer je pomagal razvijati umetno inteligenco, a je medtem\npostal zaskrbljen zaradi tehnologije in svoje vloge v njenem\nrazvoju.\n\n\"Tolažim se z običajnim izgovorom, da če jaz ne bi tega počel, bi\nnekdo drug,\" je Hinton dejal za časopis New York Times, ki je prvi\nporočal o njegovi odločitvi.\n\nKot je pojasnil v ponedeljek, je z Googla odšel, da bi lahko\nsvobodno govoril o tveganjih umetne inteligence, ne pa iz želje, da\nbi kritiziral to podjetje, za katero je dejal, da je delovalo \"zelo\nodgovorno\".\n\nDo Hintonove odločitve prihaja v času, ko vse več politikov,\norganizacij in poznavalcev opozarja na možnost, da bi novi programi\numetne inteligence lahko širili lažne informacije in ukinjali\ndelovna mesta.\n\nV ospredu razvoja tovrstnih programov so OpenAI, Microsoft in\nGoogle, podobno tehnologijo pa razvijajo tudi IBM, Amazon, Baidu in\nTencent.\n\nMarca so vidni posamezniki na področju tehnologije objavili javno\npismo s pozivom, naj podjetja za najmanj pol leta prenehajo\nrazvijati sisteme umetne inteligence, kot razlog pa so navedli\n\"velika tveganja za družbo in človeštvo\".\n\nHinton je v pogovoru za New York Times izrazil zaskrbljenost glede\nmožnosti, da bi umetna inteligenca ukinila delovna mesta in\nustvarila svet, kjer številni ljudje \"ne bodo mogli vedeti več, kaj\nje res\". Opozoril je tudi na presunljiv tempo razvoja\ntehnologije.\n\nKot je dejal, je včasih mislil, da umetna inteligenca ne bo\npametnejša od ljudi še vsaj od 30 do 50 let, celo več. \"Očitno ne\nmislim več tako,\" je dejal.\n\nŽe leta 2021 je napovedal, da bo umetna inteligenca preobrazila\ndružbo na načine, ki jih ne razumemo popolnoma in katerih učinki ne\nbodo samo dobri. Umetna inteligenca bo okrepila zdravstvo, a bo\ntudi odprla možnosti za smrtonosna avtonomna orožja, je\ndejal.\n\nwww.rtvslo.si/znanos...ije/666749\n\n7 NEVARNOSTI\n\nZnanstveniki opozarjajo: To je sedem največjih nevarnosti, ki jih\nprinaša umetna inteligenca\nSeznam znanstvenikov, ki javno opozarjajo na nevarnosti\nneregulirane umetne inteligence, se vsak dan povečuje.\n\nSeznam znanstvenikov, ki javno opozarjajo na nevarnosti\nneregulirane umetne inteligence, ki se hitro razvija v največjih\nsvetovnih tehnoloških laboratorijih, se vsak dan povečuje. Mnogi se\nsprašujejo, česa točno se strokovnjaki bojijo, ko gre za\ntehnologijo prihodnosti, ki je že del vsakdana.\n\nKratkoročno, srednjeročno in dolgoročno tveganje, da nam umetna\ninteligenca ne bo koristila, se nanaša na zmanjševanje delovnih\nmest, izgubo zasebnosti, preplavljanje javnega diskurznega prostora\nz lažnimi ali izkrivljenimi vsebinami, diskriminacijo, poglabljanje\ndružbeno- gospodarsko vrzeli, pretrese na trgih in najbolj\napokaliptična možnost - vzpon robotov ubijalcev ali vsaj njihov\npadec v napačne roke.\n\nNajnovejši znanstvenik, ki je svetu poslal dramatično sporočilo,\nGeoffrey Hinton, je eden od graditeljev sistemov za umetno\ninteligenco. Hinton je pravkar podal odstopno izjavo iz Googla,\nkjer je delal kot raziskovalec, s pojasnilom, da »želi svobodo, da\nsvetu pripoveduje o nevarnostih nadaljnjega razvoja umetne\ninteligence brez strogih pravil«.\n\nV središču kritikov je več tveganj, ki jih prinaša umetna\ninteligenca.\n\n1. Družbena manipulacija\nJe že del sveta, v katerem živimo. Družbeni mediji so namreč s\nsvojimi avtonomnimi algoritmi zelo učinkoviti pri ciljanem trženju.\nVedo, kdo smo, kaj nam je všeč in so izjemno spretni pri ugibanju,\nkaj mislimo.\n\nStrah, da umetna inteligenca zmore in na kakšen način zmore\nmanipulirati z našim vedenjem, vzbujajo primeri, med katerimi je\nnajnovejši tisti s Ferdinandom Marcosom mlajšim, ki je z vojsko\ntrolov na družbenem omrežju TikTok, osvojil glasove mlajših\nFilipincev na volitvah lani. A to ni osamljen primer.\n\nObstaja možnost, da je podjetje Cambridge Analytica leta 2016\nuporabilo zasebne podatke 50 milijonov uporabnikov Facebooka, da bi\nvplivalo na izid ameriških predsedniških volitev, na katerih je\nzmagal Donald Trump, in referendum o brexitu. Obe »odločitvi\nljudstva« sta imeli daljnosežne posledice. Recept je preprost:\nalgoritmi in zasebni podatki se uporabljajo za identifikacijo\nposameznika, ki je tarča propagande in manipulacije.\n\nŽe zdaj je dovolj težko ločiti umetno inteligenco od resničnih\nljudi, zaradi česar je vpliv umetne inteligence v virtualnem svetu\nizjemen.\n\n2. Izguba služb\nUmetna inteligenca bi lahko mnoge pustila brez dela in ta realnost\nbi lahko bila bližje, kot si mnogi mislijo. To ne velja samo za\nnajtežje poklice, temveč tudi za tiste, ki po besedah ​​Maxa Erika\nTegmarka, fizika in velikega kritika nenadzorovanega razvoja umetne\ninteligence, človeška življenja polnijo s smislom. Poleg tega\numetna inteligenca bolj ogroža dela belih ovratnikov kot fizične\ndelavce. AI se že pogosto uporablja v trženju, proizvodnji in\nzdravstvu.\n\nToda po ocenah Goldman Sachsa bi lahko računalniki popolnoma\nprevzeli 18 odstotkov delovnih mest na svetovni ravni. Strateg\nChris Messina, ustvarjalec hashtaga (#), pravi, da so naslednje\ntarče robotskih prevzemov računovodski in pravni poklici. »V tem\nsektorju bomo videli velike pretrese,« je prepričan Messina.\n\n3. Izguba zasebnosti\nRazvoj tehnologije je omogočil spremljanje in analizo vsega, kar\nposamezniki počnejo na spletu, pa tudi na fizičnem nivoju. Kamere\nso skoraj povsod, algoritmi za prepoznavanje obrazov pa dobro vedo,\nkdo je kdo. Na podlagi teh sistemov je bil zgrajen nekoliko\ngrozljiv kitajski družbeni rating program, po katerem poskuša\noceniti vedenje 1,4 milijarde Kitajcev. Obnašanja, ki se beležijo\nza ocenjevanje občanov, so kajenje v prostorih, kjer je kajenje\nprepovedano, prečkanje ceste na mestih, kjer to ni dovoljeno ali na\nprimer koliko časa so porabili za igranje video iger. Takšen Big\nBrother ne pomeni le vdora v zasebnost, temveč tudi možnost začetka\ndružbenega zatiranja.\n\n4. Diskriminacija\nNe gre samo za diskriminacijo in družbene predsodke, ki so bili\nopaženi pri strojnem učenju in kjer so rasne manjšine in ženske v\nslabšem položaju na Zahodu. Ker lahko stroji zbirajo, sledijo in\nanalizirajo podatke o posameznikih, lahko te informacije tudi\nuporabijo proti njim. Primeri vključujejo zavarovalnico, ki »ve«,\nda oseba pogosto govori po mobilnem telefonu, ali delodajalca, ki\nnoče zaposliti osebe zaradi »nizkih socialnih točk«. En primer je\nameriška policija, ki uporablja policijske algoritme za\nnapovedovanje prizorišč zločina. Na te algoritme vplivajo stopnje\naretacij, ki nesorazmerno prizadenejo črnske soseske in ustvarjajo\nbolj zatiralsko vzdušje v teh delih mest.\n\n5. Slabitev etike in dobre volje\nNa to je opozoril tudi papež Frančišek, ko je govoril o svetu, ki\nse rojeva s prihodom umetne inteligence. Nova tehnologija bo\nspremenila življenja ljudi tako kot internet v devetdesetih letih.\n»Če tako imenovani tehnološki napredek človeštva postane sovražnik\nskupnega dobrega, bo to vodilo v regresijo v obliko barbarstva, v\nkaterem narekuje zakon močnejšega,« je dejal papež.\n\nNajveč skrbi je povzročil ChatGPT, umetna inteligenca, katere\nodkritje je nedavno razburilo svetovno javnost. Uporabniki so\nnamreč z novo tehnologijo pobegnili na primer od pisanja esejev,\nkar je sprožilo razprave o vplivu na poštenost v akademskem\nživljenju, pa tudi na ustvarjalnost in umetnost.\n\n6. Samovodljivo orožje\nMnogi so prepričani, da bo jedrsko oboroževalno tekmo nadomestilo\navtonomno oboroževalno tekmo.\n\nPred nekaj leti je ruski predsednik Vladimir Putin v govoru pred\nštudenti ruske univerze izjavil: »Umetna inteligenca je prihodnost\nne le za Rusijo, ampak tudi za človeštvo. Kdor koli bo postal\nvodilni na tem področju, bo postal vladar sveta.« Leta 2016 je\n30.000 znanstvenikov podpisalo peticijo, ki je zahtevala ustavitev\nraziskav avtonomnega orožja. Toda poleg dejstva, da bi smrtonosno\norožje lahko ušlo izpod nadzora in razvilo lastno voljo, kar sodi v\nsfero hipotetičnih napovedi in ZF filmov, obstaja objektivna\nnevarnost, da takšno orožje pride v napačne roke, posameznikov ali\nskupin, ki nimajo velike vrednosti za človeško življenje. Ko bi se\nzačeli, bi jih bilo težko ustaviti ali premagati.\n\n7. Poglabljanje socialno-ekonomskih razlik in pretresi na\ntrgu\nDružbeni razkorak je ena od nevarnosti zaposlovanja na delovnem\nmestu, ki ga vodi umetna inteligenca. Ugotavljanje lastnosti\nkandidatov z analizo glasu in obraza po mnenju strokovnjakov\nprinaša tveganje diskriminacije pri zaposlovanju. Prav tako se je\nže izkazalo, da so fizičnim delavcem zaradi uvajanja avtomatizacije\npadle plače, »belim ovratnikom« pa so bolj ali manj ostali\nnepoškodovani, nekateri pa so celo izboljšali svoje plačilne\nliste.\n\nZaradi avtomatizacije poslovanja v finančnem sektorju obstaja\nbojazen, da bi lahko naslednjo veliko krizo povzročila umetna\ninteligenca. To se je že dvakrat zgodilo zaradi programske opreme,\nki je »ponorela« in z brezglavim ravnanjem povzročila kaos na\ntrgu.\n\nwww.slovenskenovice....teligenca/\n\nNajvečja nevarnost umetne inteligence je, da ljudje prezgodaj\nsklepajo, da jo razumejo.\nEliezer Yudkowsky\n\nMISEL DNEVA\n\n“Težava je, ker je digitalna tehnologija prišla v zibko. Kot povsod\nsmo starši zgled, velikokrat zelo slab. Ko dajo starši enoletnemu\notroku v roke telefon z risankami, da imajo mir, je to težava na\ndolgi rok.”\nUroš Perko, strokovni delavec v Skupnosti Srečanje\nTorek, 4.oktober 2022\nwww.primorske.si\n\nBOB DNEVA\n\n\"Spletna konferenca ti ne omogoča tega, da bi se nagnil k sosedu in\nmu šepetaje dal cinično pripombo. Zdi se mi, da izgubljamo\nsposobnosti iskrene komunikacije, spoznavanja ljudi,\ndiskusije.\"\nDr. Rok Tkavc, mikrobiolog\nPonedeljek, 17.aprila 2023\nwww.vecer.com",
    "author": "murje"
  },
  {
    "ctx": "Lekcije ChatGPT za gospodarski razvoj",
    "ctx_link": "https://www.finance.si/lekcije-chatgpt-za-gospodarski-razvoj/a/9013056",
    "upvotes": 0,
    "content": "\nBOB DNEVA\n\n\"Pri uporabi socialnih omrežij bi bila smiselna regulativa. Ne\nmoremo od staršev pričakovati, da bodo vedno vse zmogli in znali\nčisto sami. Kot pri cigaretah - bolje, da se mladim sploh ne\nprodajajo.\"\nNina Šenica, pedopsihiatrinja\nPonedeljek, 5. junija 2023\nwww.vecer.com",
    "author": "murje"
  },
  {
    "ctx": "Lekcije ChatGPT za gospodarski razvoj",
    "ctx_link": "https://www.finance.si/lekcije-chatgpt-za-gospodarski-razvoj/a/9013056",
    "upvotes": 3,
    "content": "\nmojemu menedzerju so na neki menedzerski konferenci prodali idejo,\nda do 2030 programerjev (med katerimi sem tudi sam). taisti model\nme potem cele dneve zasipa s ticketi in requesti, ki jih je treba\nnarest asap.\n\nkomaj cakam tole leto 2030, ker bi si rad vsaj malo oddahnil...",
    "author": "shevchenko"
  }
]